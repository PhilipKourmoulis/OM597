{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gclf_model.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import joblib\n",
    "import json\n",
    "import pathlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Read data\n",
    "data_filepath = pathlib.Path('train.csv')\n",
    "data = pd.read_csv(data_filepath)\n",
    "\n",
    "# Create \"dummy\" columns for categorical data\n",
    "dummy_column_mapper = {}\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        temp = pd.get_dummies(data[col], prefix=col, drop_first=True)\n",
    "        data = data.drop(columns=[col])\n",
    "        data[temp.columns] = temp\n",
    "        dummy_column_mapper[col] = temp.columns.tolist()\n",
    "\n",
    "# Save mapper for dummy columns\n",
    "with open('dummy_column_mapper.json', 'w') as fout:\n",
    "    json.dump(dummy_column_mapper, fout)\n",
    "\n",
    "# Prepare data for model training\n",
    "target = 'Exited'\n",
    "features = [col for col in data.columns if col != target]\n",
    "binary_columns = [col for col in features if sorted(data[col].unique().tolist()) == [0, 1]]\n",
    "\n",
    "X = data[features].copy()\n",
    "y = data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.30, \n",
    "    random_state=69,\n",
    ")\n",
    "\n",
    "# Save column order of training data\n",
    "with open('col_order.json', 'w') as fout:\n",
    "    json.dump(X_train.columns.tolist(), fout)\n",
    "\n",
    "# Fit scaler\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "\n",
    "# Save scaling information\n",
    "scaler_filepath = pathlib.Path('scaler_info.json')\n",
    "\n",
    "scaler_dict  = {}\n",
    "for feature, mean, scale in zip(features, scaler.mean_, scaler.scale_):\n",
    "    if feature in binary_columns:\n",
    "        scaler_dict[feature] = {\n",
    "            'mean': 0,\n",
    "            'std': 1,\n",
    "        }\n",
    "    else:\n",
    "        scaler_dict[feature] = {\n",
    "            'mean': mean,\n",
    "            'std': scale,\n",
    "        }\n",
    "        \n",
    "with open(scaler_filepath, 'w') as fout:\n",
    "    json.dump(scaler_dict, fout)\n",
    "    \n",
    "# Scale data\n",
    "for col, col_params in scaler_dict.items():\n",
    "    X_train.loc[:, col] = (X_train.loc[:, col] - col_params['mean'])/col_params['std']\n",
    "    X_test.loc[:, col] = (X_test.loc[:, col] - col_params['mean'])/col_params['std']\n",
    "\n",
    "# Fit random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'max_depth': [2, 5, 10], \n",
    "    'n_estimators': [10, 100], \n",
    "}\n",
    "\n",
    "\n",
    "rclf = GridSearchCV(RandomForestClassifier(random_state=0), params, error_score=0)\n",
    "search = rclf.fit(X_train, y_train)\n",
    "best_params = search.best_params_ \n",
    "best_params\n",
    "\n",
    "rclf = RandomForestClassifier(random_state=0, **best_params)\n",
    "rclf = rclf.fit(X_train, y_train) \n",
    "rclf.score(X_test, y_test)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gclf = gnb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Save model\n",
    "joblib.dump(gclf, 'gclf_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CreditScore': 597,\n",
       " 'Geography': 'Germany',\n",
       " 'Gender': 'Female',\n",
       " 'Age': 35,\n",
       " 'Tenure': 8,\n",
       " 'Balance': 131101.04,\n",
       " 'NumOfProducts': 1,\n",
       " 'HasCrCard': 1,\n",
       " 'IsActiveMember': 1,\n",
       " 'EstimatedSalary': 192852.67}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv(data_filepath)\n",
    "\n",
    "ckey = 0\n",
    "raw_payload = new_data.loc[ckey].to_dict()\n",
    "target = raw_payload.pop('Exited')\n",
    "\n",
    "raw_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dummy_column_mapper.json') as fin:\n",
    "    dummy_column_mapper = json.load(fin)\n",
    "    \n",
    "with open('scaler_info.json') as fin:\n",
    "    scaler_info = json.load(fin)\n",
    "    \n",
    "with open('col_order.json') as fin:\n",
    "    col_order = json.load(fin)\n",
    "    \n",
    "payload = dict(raw_payload)\n",
    "for column, dummy_columns in dummy_column_mapper.items():\n",
    "    for dummy_column in dummy_columns:\n",
    "        payload[dummy_column] = 0\n",
    "    if column in payload:\n",
    "        column_val = payload.pop(column)\n",
    "        target_column = f'{column}_{column_val}'\n",
    "        payload[target_column] = 1\n",
    "        \n",
    "for key, scaler_params in scaler_info.items():\n",
    "    if key in payload:\n",
    "        payload[key] = (payload[key] - scaler_params['mean'])/scaler_params['std']\n",
    "    else:\n",
    "        payload[key] = scaler_params['mean']\n",
    "        \n",
    "ordered_payload = {}\n",
    "for col in col_order:\n",
    "    ordered_payload[col] = payload[col]\n",
    "    \n",
    "prediction = int(gclf.predict(np.array(list(ordered_payload.values())).reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_endpoint = 'https://msba-azure-deployment.azurewebsites.net/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'App is Healthy'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(base_endpoint)\n",
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_endpoint = 'https://msba-azure-deployment.azurewebsites.net/predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.post(predict_endpoint, json=raw_payload)\n",
    "int(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 0: actual->0, prediction->0. Correct!!!\n",
      "Instance 1: actual->1, prediction->0. \n",
      "Instance 2: actual->0, prediction->0. Correct!!!\n",
      "Instance 3: actual->0, prediction->0. Correct!!!\n",
      "Instance 4: actual->0, prediction->0. Correct!!!\n",
      "Instance 5: actual->1, prediction->1. Correct!!!\n",
      "Instance 6: actual->0, prediction->0. Correct!!!\n",
      "Instance 7: actual->0, prediction->0. Correct!!!\n",
      "Instance 8: actual->1, prediction->0. \n",
      "Instance 9: actual->1, prediction->1. Correct!!!\n",
      "Instance 10: actual->0, prediction->0. Correct!!!\n",
      "Instance 11: actual->0, prediction->0. Correct!!!\n",
      "Instance 12: actual->0, prediction->0. Correct!!!\n",
      "Instance 13: actual->0, prediction->0. Correct!!!\n",
      "Instance 14: actual->1, prediction->1. Correct!!!\n",
      "Instance 15: actual->1, prediction->0. \n",
      "Instance 16: actual->0, prediction->0. Correct!!!\n",
      "Instance 17: actual->0, prediction->0. Correct!!!\n",
      "Instance 18: actual->0, prediction->0. Correct!!!\n",
      "Instance 19: actual->0, prediction->0. Correct!!!\n",
      "Instance 20: actual->0, prediction->0. Correct!!!\n",
      "Instance 21: actual->0, prediction->0. Correct!!!\n",
      "Instance 22: actual->0, prediction->0. Correct!!!\n",
      "Instance 23: actual->0, prediction->0. Correct!!!\n",
      "Instance 24: actual->0, prediction->0. Correct!!!\n",
      "Instance 25: actual->0, prediction->0. Correct!!!\n",
      "Instance 26: actual->0, prediction->0. Correct!!!\n",
      "Instance 27: actual->0, prediction->0. Correct!!!\n",
      "Instance 28: actual->0, prediction->0. Correct!!!\n",
      "Instance 29: actual->0, prediction->0. Correct!!!\n",
      "Instance 30: actual->0, prediction->0. Correct!!!\n",
      "Instance 31: actual->1, prediction->0. \n",
      "Instance 32: actual->0, prediction->0. Correct!!!\n",
      "Instance 33: actual->0, prediction->0. Correct!!!\n",
      "Instance 34: actual->0, prediction->0. Correct!!!\n",
      "Instance 35: actual->0, prediction->0. Correct!!!\n",
      "Instance 36: actual->0, prediction->0. Correct!!!\n",
      "Instance 37: actual->0, prediction->0. Correct!!!\n",
      "Instance 38: actual->0, prediction->0. Correct!!!\n",
      "Instance 39: actual->0, prediction->0. Correct!!!\n",
      "Instance 40: actual->0, prediction->0. Correct!!!\n",
      "Instance 41: actual->1, prediction->0. \n",
      "Instance 42: actual->1, prediction->0. \n",
      "Instance 43: actual->0, prediction->0. Correct!!!\n",
      "Instance 44: actual->0, prediction->0. Correct!!!\n",
      "Instance 45: actual->0, prediction->0. Correct!!!\n",
      "Instance 46: actual->0, prediction->0. Correct!!!\n",
      "Instance 47: actual->0, prediction->0. Correct!!!\n",
      "Instance 48: actual->0, prediction->0. Correct!!!\n",
      "Instance 49: actual->0, prediction->0. Correct!!!\n",
      "Instance 50: actual->1, prediction->1. Correct!!!\n",
      "Instance 51: actual->0, prediction->0. Correct!!!\n",
      "Instance 52: actual->0, prediction->0. Correct!!!\n",
      "Instance 53: actual->0, prediction->0. Correct!!!\n",
      "Instance 54: actual->0, prediction->0. Correct!!!\n",
      "Instance 55: actual->0, prediction->0. Correct!!!\n",
      "Instance 56: actual->0, prediction->0. Correct!!!\n",
      "Instance 57: actual->0, prediction->0. Correct!!!\n",
      "Instance 58: actual->1, prediction->0. \n",
      "Instance 59: actual->1, prediction->0. \n",
      "Instance 60: actual->0, prediction->0. Correct!!!\n",
      "Instance 61: actual->0, prediction->0. Correct!!!\n",
      "Instance 62: actual->0, prediction->0. Correct!!!\n",
      "Instance 63: actual->1, prediction->0. \n",
      "Instance 64: actual->1, prediction->1. Correct!!!\n",
      "Instance 65: actual->1, prediction->1. Correct!!!\n",
      "Instance 66: actual->0, prediction->0. Correct!!!\n",
      "Instance 67: actual->0, prediction->0. Correct!!!\n",
      "Instance 68: actual->0, prediction->0. Correct!!!\n",
      "Instance 69: actual->1, prediction->1. Correct!!!\n",
      "Instance 70: actual->0, prediction->0. Correct!!!\n",
      "Instance 71: actual->0, prediction->0. Correct!!!\n",
      "Instance 72: actual->0, prediction->0. Correct!!!\n",
      "Instance 73: actual->1, prediction->1. Correct!!!\n",
      "Instance 74: actual->1, prediction->0. \n",
      "Instance 75: actual->0, prediction->0. Correct!!!\n",
      "Instance 76: actual->1, prediction->1. Correct!!!\n",
      "Instance 77: actual->0, prediction->0. Correct!!!\n",
      "Instance 78: actual->0, prediction->0. Correct!!!\n",
      "Instance 79: actual->0, prediction->0. Correct!!!\n",
      "Instance 80: actual->1, prediction->1. Correct!!!\n",
      "Instance 81: actual->1, prediction->0. \n",
      "Instance 82: actual->0, prediction->0. Correct!!!\n",
      "Instance 83: actual->0, prediction->0. Correct!!!\n",
      "Instance 84: actual->1, prediction->1. Correct!!!\n",
      "Instance 85: actual->0, prediction->0. Correct!!!\n",
      "Instance 86: actual->0, prediction->0. Correct!!!\n",
      "Instance 87: actual->0, prediction->0. Correct!!!\n",
      "Instance 88: actual->1, prediction->1. Correct!!!\n",
      "Instance 89: actual->0, prediction->0. Correct!!!\n",
      "Instance 90: actual->0, prediction->0. Correct!!!\n",
      "Instance 91: actual->0, prediction->0. Correct!!!\n",
      "Instance 92: actual->0, prediction->0. Correct!!!\n",
      "Instance 93: actual->1, prediction->1. Correct!!!\n",
      "Instance 94: actual->0, prediction->0. Correct!!!\n",
      "Instance 95: actual->1, prediction->0. \n",
      "Instance 96: actual->0, prediction->0. Correct!!!\n",
      "Instance 97: actual->0, prediction->0. Correct!!!\n",
      "Instance 98: actual->0, prediction->0. Correct!!!\n",
      "Instance 99: actual->0, prediction->0. Correct!!!\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.read_csv(data_filepath)\n",
    "\n",
    "for ckey in new_data.index.tolist()[:100]:\n",
    "    raw_payload = new_data.loc[ckey].to_dict()\n",
    "    target = raw_payload.pop('Exited')\n",
    "    \n",
    "    r = requests.post(predict_endpoint, json=raw_payload)\n",
    "    prediction = int(r.text)\n",
    "    if prediction == target:\n",
    "        correct_statement = 'Correct!!!'\n",
    "    else:\n",
    "        correct_statement = ''\n",
    "\n",
    "    print(f'Instance {ckey}: actual->{target}, prediction->{prediction}. {correct_statement}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
